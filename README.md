
<img width="663" alt="Screenshot 2024-09-15 at 10 58 33 AM" src="https://github.com/user-attachments/assets/b0eb3de8-3be4-47e8-957a-50050394c684">

### LinguaVision

Traditional language learning often feels disconnected from real life, filled with repetitive memorization and monotonous habits. But languages are more than just lists of words– they surround us in our daily environments. Language learning should be immersive, dynamic, and accessible. Our approach to this problem aims to bridge the gap between language and everyday experience. Whether it’s travelers wanting to quickly pick up new vocabulary based on their surroundings, students seeking a more engaging way to learn, or anyone looking to take a break from conventional classroom-bound learning, LinguaVision opens up the world as a learning tool.

LinguaVision is a language-learning app that uses real-time object detection through your device’s camera to identify objects in your surroundings. It instantly translates the object’s name into the language of your choice, making language learning interactive and immersive. Explore the world around you and expand your vocabulary effortlessly with every snap. Additionally, by integrating No Language Left Behind (NLLB-200-Distilled), an advanced AI-based translation model developed by Meta, our app provides high-quality translations across 200 languages, including endangered and low-resource languages like Asturian, Luganda, and Urdu. This capability not only enables users to learn widely spoken languages but also plays a crucial role in preserving and revitalizing endangered languages by effectively teaching them to new learners.

### Technologies

Backend: Python, Flask, OpenCV, Threading, RESTful APIs, HuggingFace, BestTen, Intersystems (Vector Search)

Machine Learning Models: YOLO (You Only Look Once), NLLB (No Language Left Behind, Llama 3.1

Frontend: React Native, Expo, JavaScript/TypeScript, HTML, CSS, Node.js

### Check it out!

Demo Video: https://youtu.be/7eL95UyXW6M
